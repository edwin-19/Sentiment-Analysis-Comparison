{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hydraulic-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Adafactor, get_linear_schedule_with_warmup, AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inclusive-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-zimbabwe",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecological-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-method",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "native-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/filtered.csv')\n",
    "df = df.dropna()\n",
    "df['label'] = df['label'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordered-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets split our dataset\n",
    "train_df, eval_df = train_test_split(df, test_size=0.4, random_state=2021)\n",
    "eval_df, test_df = train_test_split(df, test_size=0.5, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convinced-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, df, max_length=100, set_type='train'):\n",
    "        super(T5Dataset, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        self.set_type = set_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_text = self.df['text'].iloc[index]\n",
    "        src_tokenized = self.tokenizer.encode_plus(\n",
    "            input_text, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = src_tokenized['input_ids'].squeeze()\n",
    "        src_mask = src_tokenized['attention_mask'].squeeze()\n",
    "    \n",
    "        if self.set_type == 'train':\n",
    "            labels = self.df['label'].iloc[index]\n",
    "            target_tokenized = self.tokenizer.encode_plus(\n",
    "                labels,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_token_type_ids=False,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            target_ids = target_tokenized['input_ids'].squeeze()\n",
    "            target_mask = target_tokenized['attention_mask'].squeeze()\n",
    "            \n",
    "            return {\n",
    "                'input_ids': input_ids.long(),\n",
    "                'src_mask': src_mask.long(),\n",
    "                'target_ids': target_ids.long(),\n",
    "                'target_mask': target_mask.long()\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            labels = self.df['label'].iloc[index]\n",
    "            return {\n",
    "                'input_ids': input_ids.long(),\n",
    "                'src_mask': src_mask.long(),\n",
    "                'label': labels\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spanish-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = T5Dataset(tokenizer, train_df)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "eval_dataset = T5Dataset(tokenizer, eval_df, set_type='test')\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-luxembourg",
   "metadata": {},
   "source": [
    "# Prepare T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prospective-program",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chubby-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adafactor(model.parameters(), relative_step=True, warmup_init=True, lr=None)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=500, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recorded-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(batch_text):\n",
    "    return [1 if text == 'positive' else 0 for text in batch_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sharing-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614ca00ac1604281b5f6b16d9d2f8549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d385cbe05184e74a2a9f2cf111079f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29948.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.23384080960994846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffcf0ac731b421ba819f954c476e08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24957.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'negative', 'positive']\n",
      "['positive', 'positive', 'positive']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'positive', 'negative']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['positive', 'negative', 'negative']\n",
      "['positive', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'negative', 'negative']\n",
      "['negative', 'positive', 'positive']\n",
      "['negative', 'negative', 'negative']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'negative', 'positive']\n",
      "['negative', 'positive', 'negative']\n",
      "['positive', 'positive', 'positive']\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7e5f26399e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mb_src_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mb_stc_attn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38torch17/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63d75d6343a5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m             return {\n\u001b[1;32m     51\u001b[0m                 \u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;34m'src_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        b_src_input_ids = batch['input_ids'].to(device)\n",
    "        b_src_attn_mask = batch['src_mask'].to(device)\n",
    "        \n",
    "        lm_labels = batch['target_ids'].to(device)\n",
    "        lm_labels[lm_labels[:, :] == tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=b_src_input_ids,\n",
    "            attention_mask=b_src_attn_mask,\n",
    "            labels=lm_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        scheduler.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print('Training loss:', avg_train_loss)\n",
    "    \n",
    "    # Validation mode\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        b_src_input_ids = batch['input_ids'].to(device)\n",
    "        b_stc_attn_mask = batch['src_mask'].to(device)\n",
    "                \n",
    "        outputs = model.generate(b_src_input_ids)\n",
    "        decoded_output = tokenizer.batch_decode(outputs, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "        \n",
    "        y_true.append(one_hot(batch['label']))\n",
    "        y_pred.append(one_hot(decoded_output))\n",
    "    \n",
    "    y_true = np.concatenate(y_true).astype(np.float32)\n",
    "    y_pred = np.concatenate(y_pred).astype(np.float32)\n",
    "    print('Acc: {}'.format(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stainless-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('weights/t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interior-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\n",
    "    'Life is a great journey', max_length=100,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "outputs = model.generate(inputs.to('cuda'))\n",
    "tokenizer.decode(outputs.squeeze(), clean_up_tokenization_spaces=True, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
