{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "affecting-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-chicago",
   "metadata": {},
   "source": [
    "# Load model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "julian-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/filtered.csv')\n",
    "df = df.dropna()\n",
    "df['label'] = df['label'].apply(lambda x: x.lower())\n",
    "\n",
    "# Lets split our dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.4, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hungarian-inclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('weights/t5')\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-ordinance",
   "metadata": {},
   "source": [
    "# Prepare data for evaluation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "julian-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(labels):\n",
    "    return [1 if label == 'positive' else 0 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "effective-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, df, max_length=100):\n",
    "        super(T5Dataset, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_text = self.df['text'].iloc[index]\n",
    "        src_tokenized = self.tokenizer.encode_plus(\n",
    "            input_text, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = src_tokenized['input_ids'].squeeze()\n",
    "        src_mask = src_tokenized['attention_mask'].squeeze()\n",
    "    \n",
    "        labels = self.df['label'].iloc[index]\n",
    "        return {\n",
    "            'input_ids': input_ids.long(),\n",
    "            'src_mask': src_mask.long(),\n",
    "            'label': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "black-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = T5Dataset(tokenizer, test_df)\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_loader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sticky-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3391a1d28241098116bb68e72b1a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19965.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for eval_data in tqdm(eval_loader):\n",
    "    inputs = eval_data['input_ids'].to('cuda')\n",
    "    outputs = model.generate(inputs)\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "    \n",
    "    y_true.append(one_hot_label(eval_data['label']))\n",
    "    y_pred.append(one_hot_label(decoded_outputs))\n",
    "\n",
    "y_true = np.concatenate(y_true).astype(np.float32)\n",
    "y_pred = np.concatenate(y_pred).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "conventional-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.87      0.85    319413\n",
      "         1.0       0.86      0.83      0.85    319466\n",
      "\n",
      "    accuracy                           0.85    638879\n",
      "   macro avg       0.85      0.85      0.85    638879\n",
      "weighted avg       0.85      0.85      0.85    638879\n",
      "\n",
      "MCC: 0.7029659959714913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n",
    "print('MCC: {}'.format(matthews_corrcoef(y_true, y_pred)))\n",
    "categories = ['Negative', 'Positive']\n",
    "group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "group_percentage = [\n",
    "    '{0:.2%}'.format(value) for value in cm.ravel() / cm.sum()\n",
    "]\n",
    "\n",
    "labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_percentage)]\n",
    "\n",
    "labels = np.array(labels).reshape(2, 2)\n",
    "sns.heatmap(cm, annot=labels, fmt='', xticklabels=categories, yticklabels=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-moment",
   "metadata": {},
   "source": [
    "# Single Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "geographic-specialist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Life is great, Sentiment: positive\n",
      "Input: No i dont think life is great, Sentiment: negative\n",
      "Input: I hate my job, Sentiment: negative\n",
      "Input: But i love my job, Sentiment: positive\n",
      "Input: I wonder is life really that great, no i hate it, Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "batch_inputs = [\n",
    "    'Life is great', 'No i dont think life is great', \n",
    "    'I hate my job', 'But i love my job', 'I wonder is life really that great, no i hate it'\n",
    "]\n",
    "inputs = tokenizer.batch_encode_plus(\n",
    "    batch_inputs, max_length=100,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "outputs = model.generate(inputs['input_ids'].to('cuda'))\n",
    "decoded_outputs = tokenizer.batch_decode(outputs, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "for index, output in enumerate(decoded_outputs):\n",
    "    print('Input: {}, Sentiment: {}'.format(batch_inputs[index], output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
